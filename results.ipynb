{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# data\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visual\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print('All packages imported!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 500\n",
    "mpl.rcParams['font.size'] = 9\n",
    "\n",
    "# Latex document Text width\n",
    "latex_width = 469.75502\n",
    "\n",
    "def set_size(width=latex_width, height=latex_width, fraction=1, subplots=(1, 1)):\n",
    "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
    "    \n",
    "    Credit to Jack Walton for the function.\n",
    "    Source: https://jwalton.info/Embed-Publication-Matplotlib-Latex/\n",
    "    \"\"\"\n",
    "\n",
    "    fig_width_pt = width * fraction\n",
    "    fig_height_pt = height * fraction\n",
    "    \n",
    "    inches_per_pt = 1 / 72.27\n",
    "    \n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    fig_height_in = fig_height_pt * inches_per_pt * (subplots[0] / subplots[1])\n",
    "\n",
    "    return (fig_width_in, fig_height_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_task_df(task_number):\n",
    "    if task_number not in range(1, 5):\n",
    "        raise ValueError(\"Invalid task number. Please provide a task number between 1 and 4.\")\n",
    "\n",
    "    task_fps = glob(f'ckpt/test/task_{task_number}_*/result.csv')\n",
    "    dfs = []\n",
    "\n",
    "    for fp in task_fps:\n",
    "        subject = fp.split('/')[-2].split('_')[-1]\n",
    "        df = pd.read_csv(fp)\n",
    "        df['subject'] = subject\n",
    "        dfs.append(df)\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "def loo_accuracy(df):\n",
    "    acc_df = df.groupby(['subject'])[['pred', 'true']].apply(lambda x: (x['pred'] == x['true']).mean()).reset_index()\n",
    "    acc_df.columns = ['subject', 'accuracy']\n",
    "    return acc_df\n",
    "\n",
    "\n",
    "def filter_outliers(df):\n",
    "    acc_df = loo_accuracy(df)\n",
    "    Q1 = acc_df['accuracy'].quantile(0.25)\n",
    "    Q3 = acc_df['accuracy'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "\n",
    "    filtered_subjects = acc_df[(acc_df['accuracy'] >= lower_bound)]['subject']\n",
    "    removed_subjects = acc_df[~acc_df['subject'].isin(filtered_subjects)]['subject']\n",
    "\n",
    "    if len(removed_subjects) > 0:\n",
    "        print(f\"Removed subjects: {', '.join(removed_subjects)}\")\n",
    "    else:\n",
    "        print(\"No outliers removed.\")\n",
    "    print()\n",
    "\n",
    "    return df[df['subject'].isin(filtered_subjects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_hist(df, lower_bound=0.50, save_fig=False, filename=\"\"):\n",
    "    if save_fig and len(filename) == 0:\n",
    "        raise ValueError(\"Please provide a filename to save the figure.\")\n",
    "    \n",
    "    acc_df = loo_accuracy(df)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(set_size(height=0.5*latex_width)))\n",
    "\n",
    "    bins = np.arange(lower_bound, 1.05, 0.025)\n",
    "    proportions, bins, patches = ax.hist(acc_df['accuracy'], bins=bins, weights=np.ones(len(acc_df)) / len(acc_df), edgecolor='black')\n",
    "    ax.set_xlim([lower_bound, 1])\n",
    "    '''\n",
    "    if max(proportions) % 2:\n",
    "        ax.set_ylim([0, max(proportions) + 0.02])\n",
    "    else:\n",
    "        ax.set_ylim([0, max(proportions) + 0.01])\n",
    "    '''\n",
    "    ax.set_ylim([0, 0.3])\n",
    "\n",
    "    ax.set_xlabel('Accuracy')\n",
    "    ax.set_ylabel('Proportion')\n",
    "\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_classification_report(df, save_fig=False, filename=\"\"):\n",
    "    if save_fig and len(filename) == 0:\n",
    "        raise ValueError(\"Please provide a filename to save the figure.\")\n",
    "\n",
    "    cm = confusion_matrix(df['true'], df['pred'])\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(set_size()))\n",
    "\n",
    "    cax = plt.pcolormesh(cm, cmap='viridis', vmin=0, vmax=1, edgecolors='k', linewidth=0.5)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    cbar = plt.colorbar(fraction=0.046, pad=0.04, shrink=0.5)\n",
    "    cbar.set_label('Proportion', rotation=270)\n",
    "    cbar.set_ticks(np.arange(0, 1.1, 1))\n",
    "    \n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "\n",
    "    # Add accuracy values to each entry\n",
    "    for i in range(len(cm)):\n",
    "        for j in range(len(cm)):\n",
    "            if cm[i, j] >= 0.01:\n",
    "                plt.text(j + 0.5, i + 0.5, round(cm[i, j], 2),\n",
    "                         ha='center', va='center', color='black' if cm[i, j] > 0.5 else 'white', fontsize=7)\n",
    "\n",
    "    # Add xticks for every class\n",
    "    plt.xticks(np.arange(0.5, len(cm), 1), range(len(cm)))\n",
    "    plt.yticks(np.arange(0.5, len(cm), 1), range(len(cm)))\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = False\n",
    "\n",
    "for i in range(1, 5):\n",
    "    print(\"##########\")\n",
    "    print(f\"# TASK {i} #\")\n",
    "    print(\"##########\")\n",
    "\n",
    "    task_df = load_task_df(i)\n",
    "    acc_df = loo_accuracy(task_df)\n",
    "    task_clean_df = filter_outliers(task_df)\n",
    "\n",
    "    print(acc_df.describe())\n",
    "    print(classification_report(task_df['true'], task_df['pred']))\n",
    "\n",
    "    lower_bound = math.floor(acc_df.accuracy.min() * 10.0) / 10.0\n",
    "    plot_acc_hist(task_df, lower_bound=lower_bound, save_fig=save_fig, filename=f'task_{i}_acc_hist.pdf')\n",
    "    plot_classification_report(task_df, save_fig=save_fig, filename=f'task_{i}_class_report.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
