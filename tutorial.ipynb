{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 11:06:51.474968: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from ml.config.train import cfg as cfg_train\n",
    "from ml.config.test import cfg as cfg_test\n",
    "from ml.dataset import odgt2train, odgt2test\n",
    "from ml.models import ModelBuilder, OptimizerBuilder, LRScheduleBuilder, TimingCallback\n",
    "\n",
    "print(\"All packages imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Example with static classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET:\n",
      "  LIST:\n",
      "    train: train_static_pdiot-data.odgt\n",
      "    val: val_static_pdiot-data.odgt\n",
      "  num_classes: 5\n",
      "  path: /home/jonathan/git/pdiot-ml/data/sets/pdiot-data/\n",
      "MODEL:\n",
      "  ARCH:\n",
      "    LSTM:\n",
      "      hidden_size: 0\n",
      "      num_layers: 0\n",
      "    MLP:\n",
      "      dropout: 1.0\n",
      "      hidden_size: 0\n",
      "      num_layers: 0\n",
      "  INPUT:\n",
      "    format: summary\n",
      "    sensor: all\n",
      "    window_size: 50\n",
      "TRAIN:\n",
      "  DATA:\n",
      "    batch_size: 128\n",
      "    overlap_size: 0\n",
      "  FN:\n",
      "    config: config.yaml\n",
      "    history: history.csv\n",
      "    log: log.txt\n",
      "    weight: weights.hdf5\n",
      "  LEN:\n",
      "    early_stop: 5\n",
      "    num_epoch: 5\n",
      "  LR:\n",
      "    gamma: 0.1\n",
      "    schedule: step\n",
      "    step_size: 40\n",
      "  OPTIM:\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    optim: adam\n",
      "    weight_decay: 0.0005\n",
      "  path: /home/jonathan/git/pdiot-ml/ckpt/static/\n"
     ]
    }
   ],
   "source": [
    "# fill in your directory set up here\n",
    "config_fp = '/home/jonathan/git/pdiot-ml/config/train/static.yaml'\n",
    "cfg_train.merge_from_file(config_fp)\n",
    "cfg_train.DATASET.path = '/home/jonathan/git/pdiot-ml/data/sets/pdiot-data/'\n",
    "cfg_train.TRAIN.path = '/home/jonathan/git/pdiot-ml/ckpt/static/'   \n",
    "print(cfg_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment \n",
    "train_odgt_fp = os.path.join(cfg_train.DATASET.path, cfg_train.DATASET.LIST.train)\n",
    "val_odgt_fp = os.path.join(cfg_train.DATASET.path, cfg_train.DATASET.LIST.val)\n",
    "\n",
    "train_X, train_y = odgt2train(train_odgt_fp, cfg_train.MODEL.INPUT.window_size, \n",
    "                                            cfg_train.TRAIN.DATA.overlap_size)\n",
    "val_X, val_y = odgt2train(val_odgt_fp, cfg_train.MODEL.INPUT.window_size, \n",
    "                                      cfg_train.TRAIN.DATA.overlap_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 11:06:59.865019: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 2s 5ms/step - loss: 0.7542 - acc: 0.8382 - val_loss: 0.2920 - val_acc: 0.9845 - lr: 0.0100\n",
      "Epoch 2/5\n",
      "297/297 [==============================] - 1s 5ms/step - loss: 0.2048 - acc: 0.9818 - val_loss: 0.1666 - val_acc: 0.9895 - lr: 0.0100\n",
      "Epoch 3/5\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.1363 - acc: 0.9843 - val_loss: 0.1327 - val_acc: 0.9900 - lr: 0.0100\n",
      "Epoch 4/5\n",
      "297/297 [==============================] - 2s 5ms/step - loss: 0.1135 - acc: 0.9846 - val_loss: 0.1199 - val_acc: 0.9925 - lr: 0.0100\n",
      "Epoch 5/5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.1031 - acc: 0.9847 - val_loss: 0.1131 - val_acc: 0.9925 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "model = ModelBuilder.build_classifier(cfg_train.MODEL, '', cfg_train.DATASET.num_classes)\n",
    "optimizer = OptimizerBuilder.build_optimizer(cfg_train.TRAIN.OPTIM)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "metrics = [\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "]\n",
    "\n",
    "lr_scheduler = LRScheduleBuilder.build_scheduler(cfg_train.TRAIN.LR)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=cfg_train.TRAIN.LEN.early_stop)\n",
    "\n",
    "#checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#    filepath=os.path.join(cfg_train.TRAIN.path, 'weights.hdf5'),\n",
    "#    save_weights_only=True,\n",
    "#    monitor='val_acc',\n",
    "#    mode='max',\n",
    "#    save_best_only=True)\n",
    "\n",
    "#timing_callback = TimingCallback()\n",
    "\n",
    "#history_callback = tf.keras.callbacks.CSVLogger(\n",
    "#    os.path.join(cfg_train.TRAIN.path, 'history.csv'), \n",
    "#    separator=',', \n",
    "#    append=False)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "history = model.fit(train_X, train_y, validation_data=(val_X, val_y), \n",
    "          epochs=cfg_train.TRAIN.LEN.num_epoch, \n",
    "          batch_size=cfg_train.TRAIN.DATA.batch_size,\n",
    "          callbacks=[lr_callback, \n",
    "                     early_stop_callback])\n",
    "#                     checkpoint_callback,\n",
    "#                     timing_callback,\n",
    "#                     history_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Example for task 1 with subject 29. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET:\n",
      "  path: /home/jonathan/git/pdiot-ml/data/sets/pdiot-data/\n",
      "  task: 1\n",
      "MODEL:\n",
      "  CONFIG:\n",
      "    breath: \n",
      "    dynamic: config/train/task_1/dynamic.yaml\n",
      "    motion: config/train/task_1/motion.yaml\n",
      "    static: config/train/task_1/static.yaml\n",
      "  INPUT:\n",
      "    window_size: 50\n",
      "TEST:\n",
      "  DATA:\n",
      "    batch_size: 128\n",
      "    overlap_size: 0\n",
      "  path: /home/jonathan/git/pdiot-ml/ckpt/test/task_1\n",
      "  subject: 30\n"
     ]
    }
   ],
   "source": [
    "# fill in your directory set up here\n",
    "project_dp = '/home/jonathan/git/pdiot-ml/'\n",
    "config_fp = os.path.join(project_dp, 'config/test/task_1.yaml')\n",
    "cfg_test.merge_from_file(config_fp)\n",
    "cfg_test.TEST.subject = 30\n",
    "cfg_test.DATASET.path = '/home/jonathan/git/pdiot-ml/data/sets/pdiot-data/'\n",
    "cfg_test.TEST.path = '/home/jonathan/git/pdiot-ml/ckpt/test/task_1'   \n",
    "print(cfg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment \n",
    "test_odgt_fp = os.path.join(cfg_test.DATASET.path, f'full_t{cfg_test.DATASET.task}_pdiot-data.odgt')\n",
    "test_dict = odgt2test(test_odgt_fp, cfg_test.DATASET.task,\n",
    "                                    cfg_test.TEST.subject, \n",
    "                                    cfg_test.MODEL.INPUT.window_size, \n",
    "                                    cfg_test.TEST.DATA.overlap_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_cfg_fp = os.path.join(project_dp, cfg_test.MODEL.CONFIG.dynamic)\n",
    "cfg_train.merge_from_file(motion_cfg_fp)\n",
    "motion_model = ModelBuilder.build_classifier(cfg_train.MODEL, '', 5)\n",
    "\n",
    "\n",
    "model = ModelBuilder.build_classifier(cfg_train.MODEL, '', cfg_train.DATASET.num_classes)\n",
    "optimizer = OptimizerBuilder.build_optimizer(cfg_train.TRAIN.OPTIM)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "metrics = [\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "]\n",
    "\n",
    "lr_scheduler = LRScheduleBuilder.build_scheduler(cfg_train.TRAIN.LR)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=cfg_train.TRAIN.LEN.early_stop)\n",
    "\n",
    "#checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#    filepath=os.path.join(cfg_train.TRAIN.path, 'weights.hdf5'),\n",
    "#    save_weights_only=True,\n",
    "#    monitor='val_acc',\n",
    "#    mode='max',\n",
    "#    save_best_only=True)\n",
    "\n",
    "#timing_callback = TimingCallback()\n",
    "\n",
    "#history_callback = tf.keras.callbacks.CSVLogger(\n",
    "#    os.path.join(cfg_train.TRAIN.path, 'history.csv'), \n",
    "#    separator=',', \n",
    "#    append=False)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "history = model.fit(train_X, train_y, validation_data=(val_X, val_y), \n",
    "          epochs=cfg_train.TRAIN.LEN.num_epoch, \n",
    "          batch_size=cfg_train.TRAIN.DATA.batch_size,\n",
    "          callbacks=[lr_callback, \n",
    "                     early_stop_callback])\n",
    "#                     checkpoint_callback,\n",
    "#                     timing_callback,\n",
    "#                     history_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
