{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 14:12:51.374022: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from ml.config.train import cfg as cfg_train\n",
    "from ml.config.test import cfg as cfg_test\n",
    "from ml.dataset import odgt2train, odgt2test\n",
    "from ml.models import TASK_MODEL_DICT, ModelBuilder, OptimizerBuilder, LRScheduleBuilder, TimingCallback\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"All packages imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Example with static classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET:\n",
      "  LIST:\n",
      "    train: train_static_pdiot-data.odgt\n",
      "    val: val_static_pdiot-data.odgt\n",
      "  num_classes: 5\n",
      "  path: /home/jonathan/git/pdiot-ml/data/sets/pdiot-data/\n",
      "MODEL:\n",
      "  ARCH:\n",
      "    LSTM:\n",
      "      hidden_size: 0\n",
      "      num_layers: 0\n",
      "    MLP:\n",
      "      dropout: 1.0\n",
      "      hidden_size: 0\n",
      "      num_layers: 0\n",
      "  INPUT:\n",
      "    format: summary\n",
      "    sensor: all\n",
      "    window_size: 50\n",
      "TRAIN:\n",
      "  DATA:\n",
      "    batch_size: 128\n",
      "    overlap_size: 0\n",
      "  FN:\n",
      "    config: config.yaml\n",
      "    history: history.csv\n",
      "    log: log.txt\n",
      "    weight: weights.hdf5\n",
      "  LEN:\n",
      "    early_stop: 5\n",
      "    num_epoch: 5\n",
      "  LR:\n",
      "    gamma: 0.1\n",
      "    schedule: step\n",
      "    step_size: 40\n",
      "  OPTIM:\n",
      "    lr: 0.01\n",
      "    momentum: 0.9\n",
      "    optim: adam\n",
      "    weight_decay: 0.0005\n",
      "  path: /home/jonathan/git/pdiot-ml/ckpt/static/\n"
     ]
    }
   ],
   "source": [
    "# fill in your directory set up here\n",
    "config_fp = '/home/jonathan/git/pdiot-ml/config/train/static.yaml'\n",
    "cfg_train.merge_from_file(config_fp)\n",
    "cfg_train.DATASET.path = '/home/jonathan/git/pdiot-ml/data/sets/pdiot-data/'\n",
    "cfg_train.TRAIN.path = '/home/jonathan/git/pdiot-ml/ckpt/static/'   \n",
    "print(cfg_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment \n",
    "train_odgt_fp = os.path.join(cfg_train.DATASET.path, cfg_train.DATASET.LIST.train)\n",
    "val_odgt_fp = os.path.join(cfg_train.DATASET.path, cfg_train.DATASET.LIST.val)\n",
    "\n",
    "train_X, train_y = odgt2train(train_odgt_fp, cfg_train.MODEL.INPUT.window_size, \n",
    "                                            cfg_train.TRAIN.DATA.overlap_size)\n",
    "val_X, val_y = odgt2train(val_odgt_fp, cfg_train.MODEL.INPUT.window_size, \n",
    "                                      cfg_train.TRAIN.DATA.overlap_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 14:12:58.303200: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 2s 5ms/step - loss: 0.8095 - acc: 0.8207 - val_loss: 0.3012 - val_acc: 0.9850 - lr: 0.0100\n",
      "Epoch 2/5\n",
      "297/297 [==============================] - 1s 5ms/step - loss: 0.2106 - acc: 0.9815 - val_loss: 0.1707 - val_acc: 0.9855 - lr: 0.0100\n",
      "Epoch 3/5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.1395 - acc: 0.9841 - val_loss: 0.1342 - val_acc: 0.9910 - lr: 0.0100\n",
      "Epoch 4/5\n",
      "297/297 [==============================] - 2s 7ms/step - loss: 0.1154 - acc: 0.9845 - val_loss: 0.1205 - val_acc: 0.9925 - lr: 0.0100\n",
      "Epoch 5/5\n",
      "297/297 [==============================] - 2s 6ms/step - loss: 0.1046 - acc: 0.9849 - val_loss: 0.1131 - val_acc: 0.9925 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "model = ModelBuilder.build_classifier(cfg_train.MODEL, '', cfg_train.DATASET.num_classes)\n",
    "optimizer = OptimizerBuilder.build_optimizer(cfg_train.TRAIN.OPTIM)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "metrics = [\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "]\n",
    "\n",
    "lr_scheduler = LRScheduleBuilder.build_scheduler(cfg_train.TRAIN.LR)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=cfg_train.TRAIN.LEN.early_stop)\n",
    "\n",
    "#checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#    filepath=os.path.join(cfg_train.TRAIN.path, 'weights.hdf5'),\n",
    "#    save_weights_only=True,\n",
    "#    monitor='val_acc',\n",
    "#    mode='max',\n",
    "#    save_best_only=True)\n",
    "\n",
    "#timing_callback = TimingCallback()\n",
    "\n",
    "#history_callback = tf.keras.callbacks.CSVLogger(\n",
    "#    os.path.join(cfg_train.TRAIN.path, 'history.csv'), \n",
    "#    separator=',', \n",
    "#    append=False)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "history = model.fit(train_X, train_y, validation_data=(val_X, val_y), \n",
    "          epochs=cfg_train.TRAIN.LEN.num_epoch, \n",
    "          batch_size=cfg_train.TRAIN.DATA.batch_size,\n",
    "          callbacks=[lr_callback, \n",
    "                     early_stop_callback])\n",
    "#                     checkpoint_callback,\n",
    "#                     timing_callback,\n",
    "#                     history_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Example for task 1 with subject 29. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET:\n",
      "  path: /home/jonathan/git/pdiot-ml/data/sets/pdiot-data/\n",
      "  task: 1\n",
      "MODEL:\n",
      "  CONFIG:\n",
      "    breath: \n",
      "    dynamic: config/train/task_1/dynamic.yaml\n",
      "    motion: config/train/task_1/motion.yaml\n",
      "    static: config/train/task_1/static.yaml\n",
      "  INPUT:\n",
      "    window_size: 50\n",
      "TEST:\n",
      "  DATA:\n",
      "    batch_size: 128\n",
      "    overlap_size: 0\n",
      "  path: /home/jonathan/git/pdiot-ml/ckpt/test/task_1\n",
      "  subject: 30\n"
     ]
    }
   ],
   "source": [
    "# fill in your directory set up here\n",
    "project_dp = '/home/jonathan/git/pdiot-ml/'\n",
    "config_fp = os.path.join(project_dp, 'config/test/task_1.yaml')\n",
    "cfg_test.merge_from_file(config_fp)\n",
    "cfg_test.TEST.subject = 30\n",
    "cfg_test.DATASET.path = '/home/jonathan/git/pdiot-ml/data/sets/pdiot-data/'\n",
    "cfg_test.TEST.path = '/home/jonathan/git/pdiot-ml/ckpt/test/task_1'   \n",
    "print(cfg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment \n",
    "test_odgt_fp = os.path.join(cfg_test.DATASET.path, f'full_t{cfg_test.DATASET.task}_pdiot-data.odgt')\n",
    "test_dict = odgt2test(test_odgt_fp, cfg_test.DATASET.task,\n",
    "                                    cfg_test.TEST.subject, \n",
    "                                    cfg_test.MODEL.INPUT.window_size, \n",
    "                                    cfg_test.TEST.DATA.overlap_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 0.2789 - acc: 0.9224\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 0.1350 - acc: 0.9766\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 0.1017 - acc: 0.9795\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 0s 4ms/step - loss: 0.0868 - acc: 0.9823\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.0798 - acc: 0.9832\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 14:13:14.244103: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-10 14:13:14.245304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-10 14:13:14.246286: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-10 14:13:14.419324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-10 14:13:14.421165: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-10 14:13:14.422475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-10 14:13:15.011396: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-10 14:13:15.012667: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-10 14:13:15.013621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 4s 19ms/step - loss: 1.6175 - acc: 0.1649\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 2s 20ms/step - loss: 1.4099 - acc: 0.2070\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 2s 22ms/step - loss: 1.3314 - acc: 0.2242\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.2821 - acc: 0.2379\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 2s 24ms/step - loss: 1.2494 - acc: 0.2441\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 2s 18ms/step - loss: 1.2247 - acc: 0.2509\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.2019 - acc: 0.2561\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 2s 21ms/step - loss: 1.1769 - acc: 0.2601\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 2s 21ms/step - loss: 1.1554 - acc: 0.2656\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 2s 26ms/step - loss: 1.1389 - acc: 0.2719\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 2s 19ms/step - loss: 1.1162 - acc: 0.2745\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 2s 19ms/step - loss: 1.0915 - acc: 0.2833\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 2s 21ms/step - loss: 1.0685 - acc: 0.2861\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.0515 - acc: 0.2920\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 1.0295 - acc: 0.2957\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 2s 22ms/step - loss: 1.0083 - acc: 0.3038\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 2s 23ms/step - loss: 0.9839 - acc: 0.3060\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 2s 20ms/step - loss: 0.9675 - acc: 0.3113\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 2s 21ms/step - loss: 0.9431 - acc: 0.3156\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 2s 22ms/step - loss: 0.9222 - acc: 0.3213\n",
      "Epoch 1/5\n",
      "97/97 [==============================] - 1s 7ms/step - loss: 1.1249 - acc: 0.3404\n",
      "Epoch 2/5\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 0.5470 - acc: 0.4880\n",
      "Epoch 3/5\n",
      "97/97 [==============================] - 1s 9ms/step - loss: 0.3300 - acc: 0.4972\n",
      "Epoch 4/5\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 0.2317 - acc: 0.4989\n",
      "Epoch 5/5\n",
      "97/97 [==============================] - 1s 8ms/step - loss: 0.1793 - acc: 0.4991\n"
     ]
    }
   ],
   "source": [
    "components = TASK_MODEL_DICT[cfg_test.DATASET.task]\n",
    "model_dict = {}\n",
    "for component in components:\n",
    "    component_cfg_fp = os.path.join(project_dp, cfg_test.MODEL.CONFIG[component])\n",
    "    cfg_train.merge_from_file(component_cfg_fp)\n",
    "\n",
    "    model = ModelBuilder.build_classifier(cfg_train.MODEL, '', cfg_train.DATASET.num_classes)\n",
    "    optimizer = OptimizerBuilder.build_optimizer(cfg_train.TRAIN.OPTIM)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1)\n",
    "    metrics = [\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "    ]\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    history = model.fit(test_dict['train']['X'], test_dict['train'][component], \n",
    "                        epochs=cfg_train.TRAIN.LEN.num_epoch, \n",
    "                        batch_size=cfg_test.TEST.DATA.batch_size)\n",
    "    \n",
    "    model_dict[component] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - Subject 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       1.00      1.00      1.00        15\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       0.38      0.40      0.39        15\n",
      "           6       0.70      0.93      0.80        15\n",
      "           7       0.71      0.36      0.48        14\n",
      "           8       0.38      0.40      0.39        15\n",
      "           9       0.38      0.33      0.36        15\n",
      "          10       0.71      0.80      0.75        15\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.75      0.75      0.74       179\n",
      "weighted avg       0.77      0.77      0.76       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-10 14:14:03.663628: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-10 14:14:03.665125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-10 14:14:03.666332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "model = ModelBuilder.build_hierarchical_classifier(cfg_test.DATASET.task, model_dict)\n",
    "\n",
    "# make predictions on test data using the model(s)\n",
    "pred = model(test_dict['val']['X'])\n",
    "\n",
    "# make classification report\n",
    "report = classification_report(test_dict['val']['y'], pred)\n",
    "\n",
    "# show results\n",
    "print(f'Task {cfg_test.DATASET.task} - Subject {cfg_test.TEST.subject}') \n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
